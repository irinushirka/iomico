{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = fo.load_dataset('D2S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sample: {\n",
       "     'id': '5fc0e41edb8a866086cd1454',\n",
       "     'media_type': 'image',\n",
       "     'filepath': 'C:\\\\Users\\\\1\\\\Downloads\\\\fo\\\\D2S_009300.jpg',\n",
       "     'tags': BaseList([]),\n",
       "     'metadata': None,\n",
       "     'ground_truth': <Detections: {\n",
       " \n",
       "         'detections': BaseList([\n",
       " \n",
       "             <Detection: {\n",
       " \n",
       " \n",
       "                 'id': '5fc0e41edb8a866086cd1453',\n",
       " \n",
       " \n",
       "                 '_id': '5fc0e41edb8a866086cd1453',\n",
       " \n",
       " \n",
       "                 'attributes': BaseDict({}),\n",
       " \n",
       " \n",
       "                 'label': 'banana_single',\n",
       " \n",
       " \n",
       "                 'bounding_box': BaseList([\n",
       " \n",
       " \n",
       "                     0.4166666666666667,\n",
       " \n",
       " \n",
       "                     0.2875,\n",
       " \n",
       " \n",
       "                     0.2140625,\n",
       " \n",
       " \n",
       "                     0.38958333333333334,\n",
       " \n",
       " \n",
       "                 ]),\n",
       " \n",
       " \n",
       "                 'mask': None,\n",
       " \n",
       " \n",
       "                 'confidence': None,\n",
       " \n",
       " \n",
       "                 'index': None,\n",
       " \n",
       " \n",
       "                 '_cls': 'Detection',\n",
       " \n",
       " \n",
       "             }>,\n",
       " \n",
       "         ]),\n",
       " \n",
       "         '_cls': 'Detections',\n",
       " \n",
       "     }>,\n",
       "     'prediction': None,\n",
       " }>,\n",
       " <Sample: {\n",
       "     'id': '5fc0e41edb8a866086cd1456',\n",
       "     'media_type': 'image',\n",
       "     'filepath': 'C:\\\\Users\\\\1\\\\Downloads\\\\fo\\\\D2S_009301.jpg',\n",
       "     'tags': BaseList([]),\n",
       "     'metadata': None,\n",
       "     'ground_truth': <Detections: {\n",
       " \n",
       "         'detections': BaseList([\n",
       " \n",
       "             <Detection: {\n",
       " \n",
       " \n",
       "                 'id': '5fc0e41edb8a866086cd1455',\n",
       " \n",
       " \n",
       "                 '_id': '5fc0e41edb8a866086cd1455',\n",
       " \n",
       " \n",
       "                 'attributes': BaseDict({}),\n",
       " \n",
       " \n",
       "                 'label': 'banana_single',\n",
       " \n",
       " \n",
       "                 'bounding_box': BaseList([\n",
       " \n",
       " \n",
       "                     0.45,\n",
       " \n",
       " \n",
       "                     0.2701388888888889,\n",
       " \n",
       " \n",
       "                     0.171875,\n",
       " \n",
       " \n",
       "                     0.42777777777777776,\n",
       " \n",
       " \n",
       "                 ]),\n",
       " \n",
       " \n",
       "                 'mask': None,\n",
       " \n",
       " \n",
       "                 'confidence': None,\n",
       " \n",
       " \n",
       "                 'index': None,\n",
       " \n",
       " \n",
       "                 '_cls': 'Detection',\n",
       " \n",
       " \n",
       "             }>,\n",
       " \n",
       "         ]),\n",
       " \n",
       "         '_cls': 'Detections',\n",
       " \n",
       "     }>,\n",
       "     'prediction': None,\n",
       " }>,\n",
       " <Sample: {\n",
       "     'id': '5fc0e41edb8a866086cd1458',\n",
       "     'media_type': 'image',\n",
       "     'filepath': 'C:\\\\Users\\\\1\\\\Downloads\\\\fo\\\\D2S_009302.jpg',\n",
       "     'tags': BaseList([]),\n",
       "     'metadata': None,\n",
       "     'ground_truth': <Detections: {\n",
       " \n",
       "         'detections': BaseList([\n",
       " \n",
       "             <Detection: {\n",
       " \n",
       " \n",
       "                 'id': '5fc0e41edb8a866086cd1457',\n",
       " \n",
       " \n",
       "                 '_id': '5fc0e41edb8a866086cd1457',\n",
       " \n",
       " \n",
       "                 'attributes': BaseDict({}),\n",
       " \n",
       " \n",
       "                 'label': 'banana_single',\n",
       " \n",
       " \n",
       "                 'bounding_box': BaseList([\n",
       " \n",
       " \n",
       "                     0.3692708333333333,\n",
       " \n",
       " \n",
       "                     0.29444444444444445,\n",
       " \n",
       " \n",
       "                     0.25104166666666666,\n",
       " \n",
       " \n",
       "                     0.34652777777777777,\n",
       " \n",
       " \n",
       "                 ]),\n",
       " \n",
       " \n",
       "                 'mask': None,\n",
       " \n",
       " \n",
       "                 'confidence': None,\n",
       " \n",
       " \n",
       "                 'index': None,\n",
       " \n",
       " \n",
       "                 '_cls': 'Detection',\n",
       " \n",
       " \n",
       "             }>,\n",
       " \n",
       "         ]),\n",
       " \n",
       "         '_cls': 'Detections',\n",
       " \n",
       "     }>,\n",
       "     'prediction': None,\n",
       " }>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding train samples to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\1\\\\Downloads\\\\test_banana_can.json',\n",
       " 'C:\\\\Users\\\\1\\\\Downloads\\\\test_banana_can',\n",
       " 'C:\\\\Users\\\\1\\\\Downloads\\\\predicted_banana_can_new.json')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATHs\n",
    "SAMPLES_JSON_PATH = r'C:\\Users\\1\\Downloads\\test_banana_can.json'\n",
    "SAMPLES_IMAGES_PATH = r'C:\\Users\\1\\Downloads\\test_banana_can' \n",
    "\n",
    "PREDICTIONS_PATH = r'C:\\Users\\1\\Downloads\\predicted_banana_can_new.json'\n",
    "SAMPLES_JSON_PATH, SAMPLES_IMAGES_PATH, PREDICTIONS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON\n",
    "import json\n",
    "with open(SAMPLES_JSON_PATH) as json_file: \n",
    "    samples_anns = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREDICTIONS_PATH) as json_file:\n",
    "    pred_anns = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ground truth & predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in glob.glob(SAMPLES_IMAGES_PATH + '\\\\*'):\n",
    "    sample = fo.Sample(filepath=filepath)\n",
    "    \n",
    "    for im in samples_anns['images']:\n",
    "        if im['file_name'] == filepath[-14:]:\n",
    "            image_id = im['id']\n",
    "            h = float(im['height'])\n",
    "            w = float(im['width'])\n",
    "            break\n",
    "    \n",
    "    truth_detections = []\n",
    "    for ann in samples_anns['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            cat_id = ann['category_id']\n",
    "            for cat in test_anns['categories']:\n",
    "                if cat['id'] == cat_id:\n",
    "                    label = cat['name']\n",
    "\n",
    "            bounding_box = ann['bbox']\n",
    "            bounding_box = [float(cor) for cor in bounding_box]\n",
    "            bounding_box[0], bounding_box[2] = bounding_box[0] / w, bounding_box[2] / w\n",
    "            bounding_box[1], bounding_box[3] = bounding_box[1] / h, bounding_box[3] / h\n",
    "            \n",
    "            truth_detections.append(fo.Detection(label=label, bounding_box=bounding_box))\n",
    "\n",
    "    pred_detections = []\n",
    "    for ann in pred_anns['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            cat_id = ann['category_id']\n",
    "            \n",
    "            for cat in pred_anns['categories']:\n",
    "                if cat['id'] == cat_id:\n",
    "                    label = cat['name']\n",
    "                    \n",
    "            bounding_box = ann['bbox']\n",
    "            bounding_box = [float(cor) for cor in bounding_box]\n",
    "            bounding_box[0], bounding_box[2] = bounding_box[0] / w, bounding_box[2] / w\n",
    "            bounding_box[1], bounding_box[3] = bounding_box[1] / h, bounding_box[3] / h\n",
    "            \n",
    "            confidence = 0.5  # put the confidence if it exists\n",
    "            pred_detections.append(fo.Detection(label=label, bounding_box=bounding_box, confidence=confidence))\n",
    "   \n",
    "    sample[\"ground_truth\"] = fo.Detections(detections=truth_detections)\n",
    "    sample[\"prediction\"] = fo.Detections(detections=pred_detections)\n",
    "    sample[\"tags\"] = [\"test\"]\n",
    "    ds.add_sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset (without predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = fo.Dataset(name='D2S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'C:/Users/1/Downloads/fo/' # Path to the folder with images\n",
    "ANNOTATION_PATH = 'C:/Users/1/Downloads/fo_test.json' # Path to the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(ANNOTATION_PATH) as json_file: \n",
    "    anns = json.load(json_file)\n",
    "len(anns['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in glob.glob(IMAGES_PATH + '*'):\n",
    "    sample = fo.Sample(filepath=filepath)\n",
    "    \n",
    "    for im in anns['images']:\n",
    "        if im['file_name'] == filepath[-14:]:\n",
    "            image_id = im['id']\n",
    "            h = float(im['height'])\n",
    "            w = float(im['width'])\n",
    "            break\n",
    "    \n",
    "    detections = []\n",
    "    for ann in anns['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            cat_id = ann['category_id']\n",
    "            label = anns['categories'][cat_id]['name']\n",
    "\n",
    "            bounding_box = ann['bbox']\n",
    "            bounding_box = [float(cor) for cor in bounding_box]\n",
    "            bounding_box[0], bounding_box[2] = bounding_box[0] / w, bounding_box[2] / w\n",
    "            bounding_box[1], bounding_box[3] = bounding_box[1] / h, bounding_box[3] / h\n",
    "            \n",
    "            detections.append(fo.Detection(label=label, bounding_box=bounding_box))\n",
    "\n",
    "    sample['ground_truth'] = fo.Detections(detections=detections)\n",
    "    sample['tags'] = ['train']\n",
    "    ds.add_sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.persistent = True\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting list of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D2S']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_dataset('D2S') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name:           D2S\n",
       "Media type:     image\n",
       "Num samples:    140\n",
       "Persistent:     True\n",
       "Info:           {}\n",
       "Tags:           ['test', 'train']\n",
       "Sample fields:\n",
       "    filepath:     fiftyone.core.fields.StringField\n",
       "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
       "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    prediction:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving samples to JSON (search by TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\1\\Downloads\\export_dir' already exists; export will be merged with existing files\n",
      " 100% |█████████| 20/20 [1.1s elapsed, 0s remaining, 18.2 samples/s]         \n"
     ]
    }
   ],
   "source": [
    "export_dir = r'C:\\Users\\1\\Downloads\\export_dir'\n",
    "dataset_type = fo.types.COCODetectionDataset \n",
    "ds.match_tag('test').export(export_dir=export_dir, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving samples to TFRecord (search by TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\1\\Downloads\\export_dir' already exists; export will be merged with existing files\n",
      " 100% |█████████| 20/20 [544.2ms elapsed, 0s remaining, 36.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "export_dir = r'C:\\Users\\1\\Downloads\\export_dir'\n",
    "\n",
    "dataset_type = fo.types.TFObjectDetectionDataset\n",
    "ds.match_tag('test').export(\n",
    "    export_dir=export_dir, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving samples to JSON (search by CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset:        D2S\n",
       "Media type:     image\n",
       "Num samples:    13\n",
       "Tags:           ['test']\n",
       "Sample fields:\n",
       "    filepath:     fiftyone.core.fields.StringField\n",
       "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
       "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    prediction:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "Pipeline stages:\n",
       "    1. FilterLabels(field='prediction', filter={'$in': ['$$this.label', [...]]}, only_matches=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = ['banana']\n",
    "samples = ds.filter_labels(\"prediction\", F(\"label\").is_in(CLASSES), only_matches=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\1\\Downloads\\export_dir' already exists; export will be merged with existing files\n",
      " 100% |█████████| 13/13 [730.2ms elapsed, 0s remaining, 19.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "export_dir = r'C:\\Users\\1\\Downloads\\export_dir'\n",
    "dataset_type = fo.types.COCODetectionDataset \n",
    "samples.export(export_dir=export_dir, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving samples to TFRecord (search by CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset:        D2S\n",
       "Media type:     image\n",
       "Num samples:    11\n",
       "Tags:           ['test']\n",
       "Sample fields:\n",
       "    filepath:     fiftyone.core.fields.StringField\n",
       "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
       "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    prediction:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "Pipeline stages:\n",
       "    1. FilterLabels(field='ground_truth', filter={'$in': ['$$this.label', [...]]}, only_matches=True)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = ['can']\n",
    "samples = ds.filter_labels(\"ground_truth\", F(\"label\").is_in(CLASSES), only_matches=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\1\\Downloads\\export_dir' already exists; export will be merged with existing files\n",
      " 100% |█████████| 13/13 [244.8ms elapsed, 0s remaining, 57.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "export_dir = r'C:\\Users\\1\\Downloads\\export_dir'\n",
    "dataset_type = fo.types.TFObjectDetectionDataset\n",
    "samples.export(\n",
    "    export_dir=export_dir, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
